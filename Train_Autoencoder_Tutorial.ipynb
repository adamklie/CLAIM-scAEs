{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Train an Autoencoder for single-cell RNA-seq data\n",
    "<img src=\"imgs/CLAIM_VanillaAE_basic.png\" class=\"center\" width=500/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Authorship:**\n",
    "Adam Klie, *01/22/2022*\n",
    "***\n",
    "**Description:**\n",
    "Notebook template for building and training an autoencoder for single-cell omics analysis\n",
    "\n",
    "**Notes:**\n",
    " - **Environment:** You need a Jupyter `python3` kernel with PyTorch and Sklearn installed. [See instructions for setup here.](https://github.com/adamklie/CLAIM-scAEs#environment-setup)\n",
    " - **GPU Usage:** The default data and model used below are lightweight enough to be trained on a cpu, but if you'd like to train on a larger dataset with more parameters, we recommend opening a GPU backed notebook. If you are using the `ml_env` kernel described in the above environment setup, you simply need to run the following after logging onto the cluster:\n",
    " \n",
    " ```bash\n",
    " module load cuda10.2\n",
    "jupyter-submit -p carter-gpu -A carter-gpu -t 05-00:00:00 -c 4 -m 16G -g 1 -I\n",
    "```\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Packages\n",
    "Here we load the typical base packages we will utilize throughout the exercise. We will also need to import the PyTorch library and check if we are on a GPU node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T06:21:06.386031Z",
     "start_time": "2021-04-26T06:21:06.224110Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-14T22:04:11.454795Z",
     "iopub.status.busy": "2022-02-14T22:04:11.454599Z",
     "iopub.status.idle": "2022-02-14T22:04:14.779004Z",
     "shell.execute_reply": "2022-02-14T22:04:14.778545Z",
     "shell.execute_reply.started": "2022-02-14T22:04:11.454742Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Classic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(13)\n",
    "\n",
    "# Autoreload extension\n",
    "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "    \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  If you are on a GPU, the function will return `True` and will tell you which GPU(s) you are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T22:04:14.779805Z",
     "iopub.status.busy": "2022-02-14T22:04:14.779695Z",
     "iopub.status.idle": "2022-02-14T22:04:17.748664Z",
     "shell.execute_reply": "2022-02-14T22:04:17.748163Z",
     "shell.execute_reply.started": "2022-02-14T22:04:14.779791Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a GPU? True\n",
      "Device number [0-7]: 0\n",
      "Device count: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Using a GPU? {}\".format(torch.cuda.is_available()))\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device number [0-7]: {}\".format(torch.cuda.current_device()))\n",
    "    print(\"Device count: {}\".format(torch.cuda.device_count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T22:04:19.704627Z",
     "iopub.status.busy": "2022-02-14T22:04:19.704466Z",
     "iopub.status.idle": "2022-02-14T22:04:20.143621Z",
     "shell.execute_reply": "2022-02-14T22:04:20.143266Z",
     "shell.execute_reply.started": "2022-02-14T22:04:19.704610Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can use this variable to keep track of how many epochs you've trained a model for\n",
    "epochs_trained = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset\n",
    "Here we load the preprocessed **pbmc3k** dataset. This dataset captures Peripheral Blood Mononuclear Cells (PBMC) freely available from 10X Genomics. There were originally 2,700 single cells that were sequenced on the Illumina NextSeq 500. Here we load in the raw counts for the variable genes in high quality cells. See the `Collect_Datasets_and_Preprocess.ipynb` and `Collect_Cell_Type_Labels.ipynb` notebooks for more details on the dataset and the preprocessing steps applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T22:04:22.501959Z",
     "iopub.status.busy": "2022-02-14T22:04:22.501740Z",
     "iopub.status.idle": "2022-02-14T22:04:23.325037Z",
     "shell.execute_reply": "2022-02-14T22:04:23.324696Z",
     "shell.execute_reply.started": "2022-02-14T22:04:22.501930Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 1838 genes across 2638 cells\n"
     ]
    }
   ],
   "source": [
    "# Load the raw counts of highly variable genes. We have less than 2700 cells due to previous filtering\n",
    "raw_counts = pd.read_csv(\"data/pbmc3k_raw_var_genes.tsv\", index_col=0, sep=\"\\t\")\n",
    "num_genes = raw_counts.shape[0] # rows\n",
    "num_cells = raw_counts.shape[1] # columns\n",
    "print(\"Dataset contains {} genes across {} cells\".format(num_genes, num_cells))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Standardize inputs\n",
    "Here we scale each genes expression to mean 0 and standard deviation 1 across all cells. This will improve convergence properties during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T22:04:28.451406Z",
     "iopub.status.busy": "2022-02-14T22:04:28.451241Z",
     "iopub.status.idle": "2022-02-14T22:04:31.871086Z",
     "shell.execute_reply": "2022-02-14T22:04:31.870744Z",
     "shell.execute_reply.started": "2022-02-14T22:04:28.451391Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T22:04:31.871829Z",
     "iopub.status.busy": "2022-02-14T22:04:31.871720Z",
     "iopub.status.idle": "2022-02-14T22:04:32.533902Z",
     "shell.execute_reply": "2022-02-14T22:04:32.533607Z",
     "shell.execute_reply.started": "2022-02-14T22:04:31.871814Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2638, 1838),\n",
       " array([-1.02626188e-16,  6.36263428e-16,  2.52517344e-16, ...,\n",
       "         1.89575421e-16,  2.13459105e-16, -8.80518807e-16]),\n",
       " array([1., 1., 1., ..., 1., 1., 1.]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# StandardScaler prefers samples x features \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(raw_counts.T)\n",
    "scaled_counts = scaler.transform(raw_counts.T)\n",
    "scaled_counts.shape, scaled_counts.mean(axis=0), scaled_counts.std(axis=0)  # Double check scaling was done correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Instantiate the dataloader\n",
    "[DataLoaders](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html) are fundamental PyTorch objects that interface the data you want to train with to the model you want to train. A DataLoader is essentially a Python iterator that can be looped through to pull \"batches\" of data at time. These \"batches\" of data are passed to the model during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T22:04:36.164884Z",
     "iopub.status.busy": "2022-02-14T22:04:36.164760Z",
     "iopub.status.idle": "2022-02-14T22:04:37.071937Z",
     "shell.execute_reply": "2022-02-14T22:04:37.071613Z",
     "shell.execute_reply.started": "2022-02-14T22:04:36.164868Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-20T16:11:24.609119Z",
     "start_time": "2021-05-20T16:11:24.590436Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-14T22:04:37.072640Z",
     "iopub.status.busy": "2022-02-14T22:04:37.072524Z",
     "iopub.status.idle": "2022-02-14T22:04:37.646364Z",
     "shell.execute_reply": "2022-02-14T22:04:37.646034Z",
     "shell.execute_reply.started": "2022-02-14T22:04:37.072626Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build a TensorDataset object from the scaled array, note that PyTorch likes Tensors, not numpy arrays\n",
    "dataset = TensorDataset(torch.from_numpy(scaled_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-20T16:11:57.471895Z",
     "start_time": "2021-05-20T16:11:57.302899Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-14T22:04:37.647158Z",
     "iopub.status.busy": "2022-02-14T22:04:37.647044Z",
     "iopub.status.idle": "2022-02-14T22:04:38.180224Z",
     "shell.execute_reply": "2022-02-14T22:04:38.179928Z",
     "shell.execute_reply.started": "2022-02-14T22:04:37.647134Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build a simple DataLoaders from the Dataset object\n",
    "loader = DataLoader(dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-20T16:11:58.556687Z",
     "start_time": "2021-05-20T16:11:58.534431Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-14T22:04:38.180858Z",
     "iopub.status.busy": "2022-02-14T22:04:38.180756Z",
     "iopub.status.idle": "2022-02-14T22:04:38.727266Z",
     "shell.execute_reply": "2022-02-14T22:04:38.726964Z",
     "shell.execute_reply.started": "2022-02-14T22:04:38.180844Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of training set: 2638 x torch.Size([1838])\n"
     ]
    }
   ],
   "source": [
    "# Check dims of loaders for correctness (should match n_cells x torch.Size(n_genes))\n",
    "print(\"Dimensions of training set: {} x {}\".format(len(loader.dataset), loader.dataset[0][0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# The autoencoder model\n",
    "Here we initialize a predefined autoencoder architecture (see `autoencoders.py`). The encoder's job is to take an input vector and output a lower-dimensional latent embedding; the decoder does the opposite, taking the latent embedding to reconstruct/output the input vector. The decoder architecture is a mirror of the encoder's. The input size of the encoder corresponds to the dimensions of our features (variable genes) and outputs a latent embedding of size 10. \n",
    "\n",
    "We initialize the weights using a Kaiming Uniform or He initialization (see `init_weights.py`). Each linear layer is activated with the ReLU function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>TODO</b>\n",
    "\n",
    "We provide the most basic autoencoder architecture here. This is your opportunity to explore parameters i.e. the number of hidden layers, the width per layer, etc. or try something completely different!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T22:18:30.770992Z",
     "iopub.status.busy": "2022-02-14T22:18:30.770829Z",
     "iopub.status.idle": "2022-02-14T22:18:32.253652Z",
     "shell.execute_reply": "2022-02-14T22:18:32.253277Z",
     "shell.execute_reply.started": "2022-02-14T22:18:30.770975Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load predefined model and weight initializer\n",
    "from scripts.utils import init_weights\n",
    "from scripts.dca import DCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T22:18:32.254379Z",
     "iopub.status.busy": "2022-02-14T22:18:32.254270Z",
     "iopub.status.idle": "2022-02-14T22:18:33.696892Z",
     "shell.execute_reply": "2022-02-14T22:18:33.696597Z",
     "shell.execute_reply.started": "2022-02-14T22:18:32.254365Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the model on: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DCA(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=1838, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=10, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=10, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (pi): Linear(in_features=512, out_features=1838, bias=True)\n",
       "  (mean): Linear(in_features=512, out_features=1838, bias=True)\n",
       "  (disp): Linear(in_features=512, out_features=1838, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate model and move to gpu if available\n",
    "model = DCA(raw_counts.shape[0])\n",
    "model.apply(init_weights)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Executing the model on:\", device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check what our model looks like, using a handy summary function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T22:18:33.697651Z",
     "iopub.status.busy": "2022-02-14T22:18:33.697545Z",
     "iopub.status.idle": "2022-02-14T22:18:34.946423Z",
     "shell.execute_reply": "2022-02-14T22:18:34.946077Z",
     "shell.execute_reply.started": "2022-02-14T22:18:33.697636Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T22:20:38.353163Z",
     "iopub.status.busy": "2022-02-14T22:20:38.352993Z",
     "iopub.status.idle": "2022-02-14T22:20:40.061693Z",
     "shell.execute_reply": "2022-02-14T22:20:40.061392Z",
     "shell.execute_reply.started": "2022-02-14T22:20:38.353146Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "DCA                                      --                        --\n",
       "├─Sequential: 1-1                        [256, 10]                 --\n",
       "│    └─Linear: 2-1                       [256, 512]                941,568\n",
       "│    └─ReLU: 2-2                         [256, 512]                --\n",
       "│    └─Linear: 2-3                       [256, 128]                65,664\n",
       "│    └─ReLU: 2-4                         [256, 128]                --\n",
       "│    └─Linear: 2-5                       [256, 10]                 1,290\n",
       "├─Sequential: 1-2                        [256, 512]                --\n",
       "│    └─Linear: 2-6                       [256, 128]                1,408\n",
       "│    └─ReLU: 2-7                         [256, 128]                --\n",
       "│    └─Linear: 2-8                       [256, 512]                66,048\n",
       "│    └─ReLU: 2-9                         [256, 512]                --\n",
       "├─Linear: 1-3                            [256, 1838]               942,894\n",
       "├─Linear: 1-4                            [256, 1838]               942,894\n",
       "├─Linear: 1-5                            [256, 1838]               942,894\n",
       "==========================================================================================\n",
       "Total params: 3,904,660\n",
       "Trainable params: 3,904,660\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 999.59\n",
       "==========================================================================================\n",
       "Input size (MB): 1.88\n",
       "Forward/backward pass size (MB): 13.93\n",
       "Params size (MB): 15.62\n",
       "Estimated Total Size (MB): 31.44\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will assume a batch size of 256. \n",
    "# The summary function expects you to include the expected input size as a parameter along with a batch size\n",
    "summary(model, input_size=(256, num_genes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's test out our autoencoder structure with our initialized parameters. You can use the following code block to check to see if things are being output the way you would expect. By default, the encoded dimension size should be 10 and the size of the decoded dimesion should match the variable genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T02:35:01.364063Z",
     "iopub.status.busy": "2022-02-16T02:35:01.363804Z",
     "iopub.status.idle": "2022-02-16T02:35:01.374993Z",
     "shell.execute_reply": "2022-02-16T02:35:01.374511Z",
     "shell.execute_reply.started": "2022-02-16T02:35:01.364035Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6609d2ade4b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Grab some seqs and outputs to test out on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrandom_cells\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Feed through encoder and to get bottleneck size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Grab some seqs and outputs to test out on\n",
    "indexes = np.random.choice(scaled_counts.shape[0], size=5)\n",
    "random_cells = torch.from_numpy(scaled_counts[indexes]).float().to(device)\n",
    "\n",
    "# Feed through encoder and to get bottleneck size\n",
    "encoded_outputs = model.encoder(random_cells).squeeze(dim=1)\n",
    "\n",
    "# Feed through encoder and decoder to get full output size\n",
    "outputs = model(random_cells)[0].squeeze(dim=1)\n",
    "print(\"Encoder output dimension: {}\\nDecoder output dimension: {}\".format(encoded_outputs.shape[1], outputs.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Set training optimization parameters\n",
    "\n",
    "Before we train our model, we need to instantiate a loss function that we are aiming to optimize and an algorithm for conducting that optimization. Here we use **MSE loss** to model the reconstruction of gene expression counts, and optimize using the **adaptive momentum (Adam) algorithm**. MSE and Adam are popular in deep learning (don't worry, I'm no DanQ), but feel free to play with others or define your own!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>TODO</b>\n",
    "    \n",
    "Try out different optimization strategies and loss functions. This is general to neural networks and not specific to autoencoders, but still an important set of hyperparameters to consider.\n",
    "\n",
    " - PyTorch optimizers: https://pytorch.org/docs/stable/optim.html\n",
    " - PyTorch loss functions: https://pytorch.org/docs/stable/nn.html#loss-functions\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T22:37:36.166029Z",
     "iopub.status.busy": "2022-02-14T22:37:36.165867Z",
     "iopub.status.idle": "2022-02-14T22:37:37.692210Z",
     "shell.execute_reply": "2022-02-14T22:37:37.691740Z",
     "shell.execute_reply.started": "2022-02-14T22:37:36.166013Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T22:37:37.693034Z",
     "iopub.status.busy": "2022-02-14T22:37:37.692905Z",
     "iopub.status.idle": "2022-02-14T22:37:39.056202Z",
     "shell.execute_reply": "2022-02-14T22:37:39.055771Z",
     "shell.execute_reply.started": "2022-02-14T22:37:37.693004Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.00001)\n",
    "#criterion = torch.nn.MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T20:24:55.084582Z",
     "iopub.status.busy": "2022-02-07T20:24:55.084466Z",
     "iopub.status.idle": "2022-02-07T20:24:57.623382Z",
     "shell.execute_reply": "2022-02-07T20:24:57.622990Z",
     "shell.execute_reply.started": "2022-02-07T20:24:55.084567Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scripts.autoencoders import ELBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T22:38:09.298957Z",
     "iopub.status.busy": "2022-02-14T22:38:09.298735Z",
     "iopub.status.idle": "2022-02-14T22:38:10.768524Z",
     "shell.execute_reply": "2022-02-14T22:38:10.768044Z",
     "shell.execute_reply.started": "2022-02-14T22:38:09.298928Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scripts.dca import ZINBLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_factors = (raw_counts.sum(axis=0)/raw_counts.sum(axis=0).median()).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T22:38:42.756182Z",
     "iopub.status.busy": "2022-02-14T22:38:42.756009Z",
     "iopub.status.idle": "2022-02-14T22:38:44.164254Z",
     "shell.execute_reply": "2022-02-14T22:38:44.163809Z",
     "shell.execute_reply.started": "2022-02-14T22:38:42.756165Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = ZINBLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T00:45:53.215118Z",
     "iopub.status.busy": "2022-02-16T00:45:53.214980Z",
     "iopub.status.idle": "2022-02-16T00:45:54.751809Z",
     "shell.execute_reply": "2022-02-16T00:45:54.751408Z",
     "shell.execute_reply.started": "2022-02-16T00:45:53.215101Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1940,  1.0895, -0.0272,  ..., -0.0452, -0.1377, -0.3896],\n",
       "        [-0.1940,  1.0895, -0.0272,  ..., -0.0452, -0.1377, -0.3896],\n",
       "        [-0.1940, -0.1151, -0.0272,  ..., -0.0452, -0.1377, -0.3896],\n",
       "        [-0.1940, -0.1151, -0.0272,  ..., -0.0452, -0.1377, -0.3896],\n",
       "        [-0.1940, -0.1151, -0.0272,  ..., -0.0452, -0.1377, -0.3896]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T01:31:43.337086Z",
     "iopub.status.busy": "2022-02-15T01:31:43.336959Z",
     "iopub.status.idle": "2022-02-15T01:31:44.777595Z",
     "shell.execute_reply": "2022-02-15T01:31:44.777246Z",
     "shell.execute_reply.started": "2022-02-15T01:31:43.337071Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = torch.rand(raw_counts.shape[0])\n",
    "x = random_cells[0:2].to(\"cpu\")\n",
    "eps = 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T01:31:45.478261Z",
     "iopub.status.busy": "2022-02-15T01:31:45.478143Z",
     "iopub.status.idle": "2022-02-15T01:31:47.148055Z",
     "shell.execute_reply": "2022-02-15T01:31:47.147727Z",
     "shell.execute_reply.started": "2022-02-15T01:31:45.478245Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8353, 0.8171, 0.0806,  ..., 0.6534, 0.4050, 0.5464],\n",
       "        [1.9453, 1.9028, 0.1877,  ..., 1.5217, 0.9430, 1.2724]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test * torch.tensor(scale_factors[0:2])[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T01:31:52.641515Z",
     "iopub.status.busy": "2022-02-15T01:31:52.641382Z",
     "iopub.status.idle": "2022-02-15T01:31:54.011637Z",
     "shell.execute_reply": "2022-02-15T01:31:54.011261Z",
     "shell.execute_reply.started": "2022-02-15T01:31:52.641499Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0439,  0.1422, -0.3750,  ..., -0.0305, -0.3001, -0.7471],\n",
       "        [-0.0439,  0.1422, -0.3750,  ..., -0.0305, -0.3001, -0.7471]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.lgamma(test+eps) + torch.lgamma(x+1.0) - torch.lgamma(x+test+eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T01:33:13.793047Z",
     "iopub.status.busy": "2022-02-15T01:33:13.792880Z",
     "iopub.status.idle": "2022-02-15T01:33:15.434475Z",
     "shell.execute_reply": "2022-02-15T01:33:15.434191Z",
     "shell.execute_reply.started": "2022-02-15T01:33:13.793031Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3299, dtype=torch.float64)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(random_cells[0:3].to(\"cpu\"), test, test, test, scale_factors[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "Here we actually optimize our defined loss function via our autoencoder inputs and reconstructions. We are making use of a training function designed for autoencoders that can be found in the `train.py` file. We will also use the livelossplot package to visualize our loss across training. If all goes well, you should see loss decrease at each epoch (aka iteration through the dataset), something along the lines of:\n",
    "\n",
    "![loss_plot](imgs/example_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T20:22:32.243256Z",
     "iopub.status.busy": "2022-02-02T20:22:32.243059Z",
     "iopub.status.idle": "2022-02-02T20:22:32.293273Z",
     "shell.execute_reply": "2022-02-02T20:22:32.292815Z",
     "shell.execute_reply.started": "2022-02-02T20:22:32.243204Z"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>TODO: Make-it-train!</b>\n",
    "    \n",
    "Define the number of epochs and how often to update the loss plot (default every 10 epochs). Note that updating too often will slow down training.\n",
    "<hr>\n",
    "<b>A note on training time:</b>\n",
    "    \n",
    "Using the given dataset, model architecture and learning rate, training is very fast. We were able to train a model for 1000 epochs in less than a minute on a GPU!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T01:36:18.946095Z",
     "iopub.status.busy": "2022-02-15T01:36:18.945956Z",
     "iopub.status.idle": "2022-02-15T01:36:20.438884Z",
     "shell.execute_reply": "2022-02-15T01:36:20.438530Z",
     "shell.execute_reply.started": "2022-02-15T01:36:18.946079Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scripts.train import train_DCA\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T01:36:20.439601Z",
     "iopub.status.busy": "2022-02-15T01:36:20.439493Z",
     "iopub.status.idle": "2022-02-15T01:36:21.907968Z",
     "shell.execute_reply": "2022-02-15T01:36:21.907614Z",
     "shell.execute_reply.started": "2022-02-15T01:36:20.439586Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "plot_frequency = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T01:36:58.870262Z",
     "iopub.status.busy": "2022-02-15T01:36:58.870098Z",
     "iopub.status.idle": "2022-02-15T01:37:12.195730Z",
     "shell.execute_reply": "2022-02-15T01:37:12.195429Z",
     "shell.execute_reply.started": "2022-02-15T01:36:58.870246Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss\n",
      "\tloss             \t (min:      nan, max:      nan, cur:      nan)\n",
      "Trained 100 epochs in 11.6922 seconds\n"
     ]
    }
   ],
   "source": [
    "# Make-it-train!\n",
    "tic = time.perf_counter()\n",
    "loss_history, _ = train_DCA(model=model, \n",
    "                                    dataloader=loader, \n",
    "                                    criterion=criterion, \n",
    "                                    optimizer=optimizer,\n",
    "                                    device=device,\n",
    "                                    num_epoch=num_epochs,\n",
    "                                    plot_frequency=plot_frequency)\n",
    "toc = time.perf_counter()\n",
    "epochs_trained += num_epochs\n",
    "print(f\"Trained {num_epochs:d} epochs in {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-29T03:15:43.201880Z",
     "iopub.status.busy": "2022-01-29T03:15:43.201643Z",
     "iopub.status.idle": "2022-01-29T03:15:45.325714Z",
     "shell.execute_reply": "2022-01-29T03:15:45.325245Z",
     "shell.execute_reply.started": "2022-01-29T03:15:43.201837Z"
    },
    "tags": []
   },
   "source": [
    "## Save trained model\n",
    "If you are happy with your model, save it's parameters. You can always load it in later for interpretation or to do more training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T20:45:35.244854Z",
     "iopub.status.busy": "2022-02-02T20:45:35.244739Z",
     "iopub.status.idle": "2022-02-02T20:45:36.373122Z",
     "shell.execute_reply": "2022-02-02T20:45:36.372772Z",
     "shell.execute_reply.started": "2022-02-02T20:45:35.244840Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"models\"):\n",
    "    os.makedirs(\"models\")\n",
    "torch.save(model.state_dict(), \"models/prelim_model_{}.pt\".format(epochs_trained))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Visualize latent space\n",
    "We are now ready to investigate that latent space our model has learned. We leave coming up with an awesome new analysis to the user, but we wrote some code for you to generate a two dimensional visualization of your latent space using both PCA and UMAP reduction. We added cell-type labels from the [Seurat guided clustering tutorial](https://satijalab.org/seurat/articles/pbmc3k_tutorial.html). Do you see separation between Seurat's cell-type labels?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>TODO: Visualize</b>\n",
    "    \n",
    "Use and modify the `visualize()` function to plot our model's embedding.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T20:02:20.045141Z",
     "iopub.status.busy": "2022-02-07T20:02:20.044891Z",
     "iopub.status.idle": "2022-02-07T20:02:21.286140Z",
     "shell.execute_reply": "2022-02-07T20:02:21.285664Z",
     "shell.execute_reply.started": "2022-02-07T20:02:20.045113Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scripts.utils import visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T20:03:38.060664Z",
     "iopub.status.busy": "2022-02-07T20:03:38.060495Z",
     "iopub.status.idle": "2022-02-07T20:03:40.350786Z",
     "shell.execute_reply": "2022-02-07T20:03:40.350322Z",
     "shell.execute_reply.started": "2022-02-07T20:03:38.060648Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-148d2fb032ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_cells\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/beegfs/shared/carterlab/CLAIM/auto_encoders/scripts/autoencoders.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mnormal_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstddev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/beegfs/shared/carterlab/CLAIM/auto_encoders/scripts/autoencoders.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# (batch_size, w, d) -> (batch_size, w*d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m#x = x.view(x.shape[0], -1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mh0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/ml_env/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/ml_env/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/ml_env/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/ml_env/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/ml_env/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1690\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "model.encode(random_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T20:02:21.286946Z",
     "iopub.status.busy": "2022-02-07T20:02:21.286835Z",
     "iopub.status.idle": "2022-02-07T20:02:22.735076Z",
     "shell.execute_reply": "2022-02-07T20:02:22.734508Z",
     "shell.execute_reply.started": "2022-02-07T20:02:21.286932Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-61766639687b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlatent_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "latent_data = model._encoder(loader.dataset.tensors[0].float().to(device))[0].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-07T20:02:22.735559Z",
     "iopub.status.idle": "2022-02-07T20:02:22.735716Z",
     "shell.execute_reply": "2022-02-07T20:02:22.735638Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cell_ids = [col[0] for col in raw_counts.columns.str.split(\"-\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-07T20:02:22.736144Z",
     "iopub.status.idle": "2022-02-07T20:02:22.736313Z",
     "shell.execute_reply": "2022-02-07T20:02:22.736234Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize(latent_embedding=latent_data, cellids=cell_ids, metadata_file=\"data/pbmc3k_SeuratMetadata.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So how'd you do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we used Scanpy to download the data, we will start by comparing to them. Here's what Scanpy's tutorial outputs on 40 PCs, 10 nearest neighbors and default UMAP settings. They use the same preprocessing strategy we used for this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![scanpy_pbm3k](imgs/pbmc3k_100_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about Seurat? They have a slightly different pipeline. These were the labels you used for you visualization as well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![seurat_pbm3k](imgs/pbmc3k_Seurat.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# References"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 ml_env",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-showcode": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
